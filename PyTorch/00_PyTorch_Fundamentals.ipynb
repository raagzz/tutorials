{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOAd20gNbmLLicQ1u7jIc7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raagzz/tutorials/blob/main/PyTorch/00_PyTorch_Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing PyTorch\n",
        "---"
      ],
      "metadata": {
        "id": "pFNM8RA_CFSA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QsNtHOprCCaC",
        "outputId": "801b5e74-78dc-44c2-bc14-2f8b498969d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Tensors\n",
        "---"
      ],
      "metadata": {
        "id": "oQ_FEsk3CXeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tensors are the fundamental building blocks of Machine Learning.\n",
        "- Their job is to represent data in a numerical way."
      ],
      "metadata": {
        "id": "i1bo-uhoQy8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating tensors\n",
        "\n",
        "- A Scalar is a single number i.e. a zero dimensional tensor.\n"
      ],
      "metadata": {
        "id": "PyA4g-uaDOQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = torch.tensor(7)\n",
        "scalar  # Although scalar is a single number, it's of type 'torch.Tensor'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eBz1dmPDTqu",
        "outputId": "c42b9a02-4820-4b7f-a063-36aeb6a3b021"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim # Check the dimensions of a tensor using the 'ndim' attribute"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZIDNUbOCMxx",
        "outputId": "47845a12-7297-434f-fb0d-030f7cbe3e15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.item()   # To retrieve the number from the tensor (as Python Int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD6lG8wzDsjX",
        "outputId": "51be5eb1-08e2-472f-a080-428762148a73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A vector is a single dimension tensor but can contain many numbers."
      ],
      "metadata": {
        "id": "1okgefwnHPnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpWt713NEJi1",
        "outputId": "be35e071-6b01-47bf-8d42-1a44cc05c6b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> You can tell the number of dimensions a tensor in PyTorch has by the number of square brackets on the outside ([) and you only need to count one side."
      ],
      "metadata": {
        "id": "Htj8RHSpH1A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim # Check the number of dimensions of vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XyES7WZHeiZ",
        "outputId": "277ddbf5-af51-4e22-bf11-c91e36e082da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape    # Tells you how the elements inside them are arranged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwIFMVK_Hh67",
        "outputId": "52ea226c-1ae3-457e-dba9-907888127217"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 0]])\n",
        "MATRIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYzdhx2sH8PQ",
        "outputId": "d2b8c5f7-df3c-4243-8401-53b4dbe4aad8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7, 8],\n",
              "        [9, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Matrices are as flexible as vectors, except they've got an extra dimension."
      ],
      "metadata": {
        "id": "Ytg0Wh2sIQqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_OLTV_hIOCu",
        "outputId": "edf55de1-01a7-4347-8c32-4011bdf919b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUEgmNu2IZFR",
        "outputId": "5b47ae5e-9e43-4016-810f-701c7aa06e2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get the output `torch.Size([2, 2])` because `MATRIX` is two elements deep and two elements wide."
      ],
      "metadata": {
        "id": "PST_M2ibIfIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9EMOaRSIbfv",
        "outputId": "6ed2bb23-f287-499c-893c-8f448f8dfa9a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IHorROdI4MV",
        "outputId": "0b79b5fb-f47d-40e9-a54c-a55596f739df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zG-bLlTI6rn",
        "outputId": "c67e6a00-b497-4dfb-b123-dd966657b634"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)"
      ],
      "metadata": {
        "id": "6VdSjc7pJVzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> In practice, you'll often see scalars and vectors denoted as lowercase letters such as `y` or `a`. And matrices and tensors denoted as uppercase letters such as `X` or `W`."
      ],
      "metadata": {
        "id": "8TqTtuZKJhSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![link text](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
      ],
      "metadata": {
        "id": "dw7EtIMvJ0r-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random tensors\n",
        "\n",
        "- When building a machine learning model with PyTorch, we start out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n",
        "\n",
        "- As a data scientist, you can define how the machine learning model starts *(initialization)*, looks at data *(representation)* and updates *(optimization)* its random numbers."
      ],
      "metadata": {
        "id": "KOVNgt2OKE34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(size=(224, 224, 3)) # create a tensor of random numbers\n",
        "random_tensor.shape, random_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vyh-TvwJI8_d",
        "outputId": "dda26d1a-c78c-421f-d1b5-d129fd3bd427"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeros and ones\n",
        "\n",
        "- Sometimes we just want to fill with zeros or ones. For example, when masking the values."
      ],
      "metadata": {
        "id": "MHAC5SkDLG6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = torch.zeros(size=(3, 4))    # Create a tensor of all zeros\n",
        "zeros, zeros.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeKMBAOfKvuQ",
        "outputId": "09523e89-2d29-4a55-a49d-cc58c112ee55"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(size=(3, 4))\n",
        "ones, ones.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j7HCMaCLbuf",
        "outputId": "55a33b69-81de-4037-ffd3-7def512aad67"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a range and tensors like\n",
        "\n",
        "- Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100."
      ],
      "metadata": {
        "id": "msvp5PeHLwYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "zero_to_ten, zero_to_ten.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s5UNkLsLwJK",
        "outputId": "5f625bb0-83df-492e-9be0-fd3d2d2efa5a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sometimes you might want one tensor of a certain type with the same shape as another tensor."
      ],
      "metadata": {
        "id": "MBUi9UGWMEQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
        "ten_ones = torch.ones_like(input=zero_to_ten)\n",
        "ten_zeros, ten_ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uBtL944MEBW",
        "outputId": "da8b3a87-a906-4dfd-f1ff-aab29bcd8bd3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor datatypes\n",
        "\n",
        "- Most common type is `torch.float32` or `torch.float` (default), referred to as *32-bit floating point*.\n",
        "\n",
        "- There are 16-bit `torch.float16` or `torch.half` and 64-bit `torch.float64` or `torch.double`\n",
        "\n",
        "- There are also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
        "\n",
        "> The reason for all of these is to do with **precision** in computing."
      ],
      "metadata": {
        "id": "FB9M9lm4Ma-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHhns2idLlYI",
        "outputId": "f92b10ac-b80d-437e-a173-39095cb51957"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Aside from **shape** issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are **datatype** and **device** issues."
      ],
      "metadata": {
        "id": "_et9nFXfN__y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16)\n",
        "\n",
        "float_16_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvFbOc3PN1cg",
        "outputId": "8e0d1b4a-7840-46c8-bc77-9d900d5159e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting information from tensors\n",
        "---"
      ],
      "metadata": {
        "id": "zJPCpYa2Qq8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
        "- `dtype` - what datatype are the elements within the tensor stored in?\n",
        "- `device` - what device is the tensor stored on? (usually GPU or CPU)"
      ],
      "metadata": {
        "id": "rdKJmiqKQ-BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "print(some_tensor)\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL4ElI9fOIKJ",
        "outputId": "03dbe19b-188c-4455-f4c8-25b6b83297ea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3755, 0.8068, 0.9972, 0.5519],\n",
            "        [0.7255, 0.0275, 0.6378, 0.7342],\n",
            "        [0.1702, 0.0445, 0.5495, 0.6003]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulating tensors (tensor operations)\n",
        "---"
      ],
      "metadata": {
        "id": "RvzWAAEwSveE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A machine learning model learns by investigating data represented as tensors, and performing a series of operations on them to create a representation of the patterns in the input data.\n",
        "- They can be addition, subtraction, multiplication (element-wise), division or matrix multiplication."
      ],
      "metadata": {
        "id": "Nz_qNaKwS5uR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic operations"
      ],
      "metadata": {
        "id": "LjOFgFYATTKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-dZ0UuNSpYD",
        "outputId": "d2546e45-376a-4ec2-9587-15ecd4e34ed9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBy__ndHTZqV",
        "outputId": "09578c96-7fd5-4c8d-b7f9-31654fa5d034"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tensor - 10 # Subtract and reassign\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_kFTmfRTck1",
        "outputId": "ddb08b09-6aa9-43c4-c0b4-2d2eb55d1f4e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tensor + 10 # Add and reassign\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdr06nODTlUt",
        "outputId": "b4b3d463-a9a6-4ac2-c19d-b91fe9772d99"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Can also use built-in functions."
      ],
      "metadata": {
        "id": "-ZdT6rIbTs8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.multiply(tensor, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGQhjq3VTpVR",
        "outputId": "931a38f0-3a1a-4ab6-e4fa-e61d5366a88d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor * tensor # Element-wise multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEXEHGTPT6k3",
        "outputId": "e8da8257-038c-4598-973c-b878ec393971"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "1. The **inner dimensions** must match.\n",
        "2. The resulting matrix has the shape of **outer dimensions**.\n"
      ],
      "metadata": {
        "id": "dDW06D33UK9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TALNy4neUB9J",
        "outputId": "b34a86c1-3f23-48f0-d592-07c64821febf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> You can do matrix multiplication by hand but it's not recommended."
      ],
      "metadata": {
        "id": "SyyXOLlVVFtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Matrix multiplication by hand\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNe8ZhLcU3Ka",
        "outputId": "89d9f00c-3550-4dd2-8a63-7f280f134c96"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 833 µs, sys: 8 µs, total: 841 µs\n",
            "Wall time: 790 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tensor @ tensor # Can also use the \"@\" symbol for matrix multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VowC9StnVOua",
        "outputId": "4ba2bff1-777d-43b3-e7a8-f3d2b44fb6ec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 79 µs, sys: 14 µs, total: 93 µs\n",
            "Wall time: 95.8 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Most common errors in deep learning (shape errors)\n",
        "---"
      ],
      "metadata": {
        "id": "LreddvLtVrFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "8ehb2VF9VYfK",
        "outputId": "3a2dfa89-b4a5-4c6d-8447-1a6e0c4bf3de"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-5893e600ebdf>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                          [9, 12]], dtype=torch.float32)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (this will error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can make matrix multiplication work between tensor_A and tensor_B by making their inner dimensions match.\n",
        "\n",
        "- One of the ways to do this is with a transpose."
      ],
      "metadata": {
        "id": "PhQ_0exKV6wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCC8AJOQV3ks",
        "outputId": "2e6dcd5d-fed9-4ec8-deaa-241b0de6baa3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mm(tensor_A, tensor_B.T) # You can also use torch.mm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFDKZ_nQWaM6",
        "outputId": "fb18f83f-a583-46e7-c287-d6f6e79865e9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear() module\n",
        "\n",
        "The torch.nn.Linear() module, also known as a **feed-forward layer** or **fully connected layer**, implements a matrix multiplication between an input `x` and a weights matrix `A`.\n",
        "\n",
        "$$ y = x\\cdot{A^T} + b $$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $x$ is the input to the layer.\n",
        "- $A$ is the weights matrix created by the layer, starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data.\n",
        "- $b$ is the bias term used to slightly offset the weights and inputs.\n",
        "- $y$ is the output (manipulating input to discover patterns in it)."
      ],
      "metadata": {
        "id": "RnBRdA9bXJ5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42) # to make it reproducible\n",
        "\n",
        "# in_features = matches inner dimensions\n",
        "# out_features = describes outer value\n",
        "linear = torch.nn.Linear(in_features=2, out_features=6)\n",
        "x = tensor_A\n",
        "output = linear(x)\n",
        "print(f\"Input shape: {x.shape}\\n\")\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDf70XfCWKR8",
        "outputId": "5a71d89e-667c-45f3-aade-f310d099daf7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([3, 2])\n",
            "\n",
            "Output:\n",
            "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
            "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
            "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Output shape: torch.Size([3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding min, max, mean, sum (aggregation)"
      ],
      "metadata": {
        "id": "LKvzbpejZHQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C0R0iexYJlu",
        "outputId": "7bd620cb-02e6-4a60-dbd0-3fa7bfb38c88"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Some methods such as `torch.mean()` require tensors to be in `torch.float32` or another specific datatype, otherwise the operation will fail."
      ],
      "metadata": {
        "id": "e7u5pQRNZuW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.min(), x.max(), x.type(torch.float32).mean(), x.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNtSTuMfZPSL",
        "outputId": "1537fab4-b4f7-4492-e301-c5392ef2ebe4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(90), tensor(45.), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also do the same as above with torch methods.\n",
        "torch.min(x), torch.max(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En2GFd1BZUre",
        "outputId": "7b4b2b2c-1f9e-4652-b306-80b81bcad194"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(90), tensor(45.), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional min/max\n"
      ],
      "metadata": {
        "id": "_FoHoJf4aU2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Index where max value occurs: {x.argmax()}\")\n",
        "print(f\"Index where min value occurs: {x.argmin()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQGmqz-oaDQr",
        "outputId": "f234aee5-9757-4906-e377-f10e04192918"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index where max value occurs: 9\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change tensor datatype\n"
      ],
      "metadata": {
        "id": "901q2fa3ajJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(10., 100., 10.)\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKOW8f5uabpO",
        "outputId": "24a01a65-63fd-4bf7-ceac-fd999c4c0f4b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_float16 = tensor.type(torch.float16)\n",
        "tensor_float16.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3syj1c7aos6",
        "outputId": "ebf74ecc-4716-4223-ed01-6e1f3d40b225"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_int8 = tensor.type(torch.int8)\n",
        "tensor_int8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFOxldqiap9Y",
        "outputId": "24fd0772-95e0-4ae8-bf9a-793a2d4289f6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing"
      ],
      "metadata": {
        "id": "pjoWbwPbbIQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1., 8.)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkpVBmkoazRt",
        "outputId": "81bb6721-f5f8-4a6b-ed0d-95cafd312d19"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Reshapes `input` to `shape` (if compatible)."
      ],
      "metadata": {
        "id": "KbD9pcekb3jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped = x.reshape(1, 7)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yfWJZ8jbne4",
        "outputId": "dc29940b-ca0b-49f6-a2d7-002de9b41256"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor."
      ],
      "metadata": {
        "id": "EAAai0BEb9-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = x.view(1, 7)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZo8qRXHbu8M",
        "outputId": "ebb6af8d-cb10-4799-d0eb-842eb2278cf6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing the view changes the original tensor too\n",
        "z[:, 0] = 5\n",
        "z, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViUbqvkKcnMX",
        "outputId": "c091a54f-bcb2-40ff-8d74-29b543dc9dd5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **In-place operations:** Operations that store the result into the operand are called *in-place*. They are denoted by a _ suffix. For example: `x.copy_(y)`, `x.t_()`, will change x."
      ],
      "metadata": {
        "id": "FDdHoVhIm7t7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size."
      ],
      "metadata": {
        "id": "R7EjZIbYcEjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_stacked_0 = torch.stack([x, x, x, x], dim=0)\n",
        "x_stacked_1 = torch.stack([x, x, x, x], dim=1)\n",
        "\n",
        "x_stacked_0, x_stacked_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dd-lCj6cE3t",
        "outputId": "37ba97e9-84e1-4079-e3ce-bfcc698715c1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
              "         [5., 2., 3., 4., 5., 6., 7.],\n",
              "         [5., 2., 3., 4., 5., 6., 7.],\n",
              "         [5., 2., 3., 4., 5., 6., 7.]]),\n",
              " tensor([[5., 5., 5., 5.],\n",
              "         [2., 2., 2., 2.],\n",
              "         [3., 3., 3., 3.],\n",
              "         [4., 4., 4., 4.],\n",
              "         [5., 5., 5., 5.],\n",
              "         [6., 6., 6., 6.],\n",
              "         [7., 7., 7., 7.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> `torch.cat()` concatenates the given sequence in the given dimension.\n",
        "> `torch.stack()` concatenates the given sequence along a new dimension."
      ],
      "metadata": {
        "id": "fKnodXJMmM3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_stacked_0 = torch.cat([x, x, x, x], dim=0)\n",
        "\n",
        "# This will error\n",
        "# x_stacked_1 = torch.cat([x, x, x, x], dim=1)\n",
        "\n",
        "x_stacked_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCeoPeWemcuo",
        "outputId": "7dbff031-990b-4da7-d741-844d0339e1a7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 2., 3., 4., 5., 6., 7., 5., 2., 3., 4., 5., 6., 7., 5., 2., 3., 4.,\n",
              "        5., 6., 7., 5., 2., 3., 4., 5., 6., 7.])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Squeezes `input` to remove all the dimenions with value `1`."
      ],
      "metadata": {
        "id": "r54H_wrdcFHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_squeezed = x_reshaped.squeeze()\n",
        "x_squeezed, x_squeezed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSdjZJwlcFrW",
        "outputId": "1e05819e-1ecd-46ab-a37c-c378470dfc69"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Returns `input` with a dimension value of `1` added at a specific index of dim."
      ],
      "metadata": {
        "id": "bCqhH8WkcF3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "x_unsqueezed, x_unsqueezed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BwUj9zKcGK9",
        "outputId": "16de93f0-b696-49b8-ce45-6373dc4f5f5b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Returns a **view** of the original `input` with its dimensions permuted (rearranged) to `dims`."
      ],
      "metadata": {
        "id": "319HH8hIcR0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "x_permuted = x_original.permute(2, 0, 1)\n",
        "\n",
        "x_original.shape, x_permuted.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOt1ZsgxcSId",
        "outputId": "d7632037-af2f-4714-f99d-a2e0baf8d909"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), torch.Size([3, 224, 224]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing (selecting data from tensors)\n",
        "---"
      ],
      "metadata": {
        "id": "9ucMK9Evein7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaWvrmgvebd_",
        "outputId": "05e2deef-f58e-45c2-f681-224044d119e2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Indexing values goes *outer dimension -> inner dimension*."
      ],
      "metadata": {
        "id": "L6u41EzQevit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x[0], x[0][0], x[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2f7KnK9euPv",
        "outputId": "9ab3ad2a-e21f-4d44-a243-4c75210a8e73"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]),\n",
              " tensor([1, 2, 3]),\n",
              " tensor(1))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can also use `:` to specify \"all values in this dimension\" and then use a comma (`,`) to add another dimension."
      ],
      "metadata": {
        "id": "7WtfBaKoe5-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of 0th dim and 0 index of 1st dim\n",
        "print(x[:, 0])\n",
        "# Get all values of 0th & 1st dims but only index 1 of 2nd dim\n",
        "print(x[:, :, 1])\n",
        "# Get all values of 0 dim but only index 1  of 1st and 2nd dim\n",
        "print(x[:, 1, 1])\n",
        "# Get index 0 of 0th and 1st dim and all values of 2nd dim\n",
        "print(x[0, 0, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glznh2wQet8G",
        "outputId": "8aca4f21-8af4-440b-df8f-c7e8b6f9b199"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3]])\n",
            "tensor([[2, 5, 8]])\n",
            "tensor([5])\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch tensors and Numpy\n",
        "---"
      ],
      "metadata": {
        "id": "CZQ8_zx4r_Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugi5m6ClfCAY",
        "outputId": "f344f12c-a77d-4ec6-b87a-378545b519eb"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> By default, NumPy arrays are created with the datatype `float64` and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above). However, many PyTorch calculations default to using `float32`."
      ],
      "metadata": {
        "id": "b8T52lkDsQoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwkBRed0sLjs",
        "outputId": "1449a0f2-8c07-4a2b-b7d1-621f2f070fcd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reproducibility\n",
        "---"
      ],
      "metadata": {
        "id": "e2AK05gntFDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
        "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
        "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
        "random_tensor_A == random_tensor_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mISclgMls0kr",
        "outputId": "6b2b81ec-089f-4998-dea7-080f1e0adfba"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n",
            "        [0.7687, 0.4566, 0.5745, 0.9200],\n",
            "        [0.3230, 0.8613, 0.0919, 0.3102]])\n",
            "\n",
            "Tensor B:\n",
            "tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n",
            "        [0.3743, 0.5220, 0.1336, 0.9666],\n",
            "        [0.9754, 0.8474, 0.8988, 0.1105]])\n",
            "\n",
            "Does Tensor A equal Tensor B? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "RANDOM_SEED=42\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Have to reset the seed every time a new rand() is called\n",
        "# Without this, tensor_D would be different to tensor_C\n",
        "torch.random.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
        "random_tensor_C == random_tensor_D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElwOJwRrvVN3",
        "outputId": "98ee6a2b-bc6c-47f8-a691-03ba2bab22e8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Does Tensor C equal Tensor D? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running tensors on GPUs\n",
        "---"
      ],
      "metadata": {
        "id": "sORBhHcAxtma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GPUs peform matrix multiplications much faster than CPUs."
      ],
      "metadata": {
        "id": "Aok-frO_yLrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi # To check access to a Nvidia GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT3uTc46vhqY",
        "outputId": "02f464f1-41ed-4a94-ec47-05c38e390b3b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec  7 14:56:17 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting PyTorch to run on GPU"
      ],
      "metadata": {
        "id": "gGb0isB8ylnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP5t20L8yX_k",
        "outputId": "547f4e05-3074-43af-8a09-46ac8c6701cd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To run **device-agnostic code**, use this practice so our PyTorch code will use available device."
      ],
      "metadata": {
        "id": "Rx4LTLIay3Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m4-Fgu16yrVe",
        "outputId": "08fe0590-0999-4b2f-e279-9fdef2ce53fe"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count() # count number of GPUs PyTorch has access to"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05rpjqDgy0Ew",
        "outputId": "3b6b5ccb-4b89-44fb-bff5-1e7fb3d1b669"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting tensors (and models) on the GPU\n",
        "\n",
        "- Putting a tensor on GPU using `to(device)` returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them."
      ],
      "metadata": {
        "id": "BmecudpWz-1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3]) # on CPU\n",
        "\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SeZ1UFXzwGq",
        "outputId": "f22b26a5-f61f-4cd8-a45b-6270e5e4e6e7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving tensors back to CPU\n",
        "\n",
        "- Have to do this if we want to interact with tensors using Numpy."
      ],
      "metadata": {
        "id": "YfNidz0r0be5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu.numpy() # If on GPU, can't transform to NumPy (error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "DZJrC50e0T21",
        "outputId": "8cd0a51d-70bf-431e-a580-3d089909381c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-a43b94429298>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# If on GPU, can't transform to NumPy (error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_cpu = tensor_on_gpu.cpu().numpy() # copy the tensor back to cpu\n",
        "tensor_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fypPKj5M0rU-",
        "outputId": "49ef5e8e-152a-4c9d-c178-61a86ded8b95"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU."
      ],
      "metadata": {
        "id": "OKRlt1lp1FNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOYlaLjF1AHI",
        "outputId": "9ca4fdc4-a77a-43ea-b48e-d37b7c9670d1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises\n",
        "---"
      ],
      "metadata": {
        "id": "JyLX9AN91stl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Documentation reading - See the documentation on [torch.Tensor](https://pytorch.org/docs/stable/tensors.html#torch-tensor) and for [torch.cuda](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics).\n",
        "\n",
        "- Spend 1-hour going through the [PyTorch basics tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
        "- To learn more on how a tensor can represent data, see this video: [What's a tensor?](https://youtu.be/f5liqUk0ZTw)"
      ],
      "metadata": {
        "id": "LFOs1uyPn0Ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create a random tensor with shape (7, 7)."
      ],
      "metadata": {
        "id": "qtk-lPWPGRpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "tensor = torch.rand(7, 7)\n",
        "tensor, tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wypsp26hGUFh",
        "outputId": "c6d0c724-3fca-4a79-c7b4-019df6f93e38"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.8694, 0.5677, 0.7411, 0.4294, 0.8854, 0.5739, 0.2666],\n",
              "         [0.6274, 0.2696, 0.4414, 0.2969, 0.8317, 0.1053, 0.2695],\n",
              "         [0.3588, 0.1994, 0.5472, 0.0062, 0.9516, 0.0753, 0.8860],\n",
              "         [0.5832, 0.3376, 0.8090, 0.5779, 0.9040, 0.5547, 0.3423],\n",
              "         [0.6343, 0.3644, 0.7104, 0.9464, 0.7890, 0.2814, 0.7886],\n",
              "         [0.5895, 0.7539, 0.1952, 0.0050, 0.3068, 0.1165, 0.9103],\n",
              "         [0.6440, 0.7071, 0.6581, 0.4913, 0.8913, 0.1447, 0.5315]]),\n",
              " torch.Size([7, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7)"
      ],
      "metadata": {
        "id": "SNBiFzIXGZ6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2 = torch.rand(1, 7)\n",
        "torch.matmul(tensor, tensor_2.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INxTlewkG4oE",
        "outputId": "977ac111-da46-41f6-d5f8-98a57d8f18e6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.9625],\n",
              "        [1.0950],\n",
              "        [0.9967],\n",
              "        [1.8910],\n",
              "        [1.9205],\n",
              "        [1.0674],\n",
              "        [1.6949]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Set the random seed to 0 and do exercises 2 & 3 over again."
      ],
      "metadata": {
        "id": "7uZC2FOXHDwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "tensor = torch.rand(7, 7)\n",
        "tensor_2 = torch.rand(1, 7)\n",
        "torch.matmul(tensor, tensor_2.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbRVRUeyHH3P",
        "outputId": "aa90c331-a7d9-44e0-946c-29aadd17a97d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.8542],\n",
              "        [1.9611],\n",
              "        [2.2884],\n",
              "        [3.0481],\n",
              "        [1.7067],\n",
              "        [2.5290],\n",
              "        [1.7989]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: you'll need to look into the documentation for torch.cuda for this one). If there is, set the GPU random seed to 1234."
      ],
      "metadata": {
        "id": "z6xnzuiaHXcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.manual_seed(1234)"
      ],
      "metadata": {
        "id": "hgKQjDzUHao2"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed)."
      ],
      "metadata": {
        "id": "6aGQoQ8RIY9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1234)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tensor_A = torch.rand(2, 3).to(device)\n",
        "tensor_B = torch.rand(2, 3).to(device)\n",
        "\n",
        "tensor_A, tensor_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4irQhlmIefY",
        "outputId": "0db0f93a-bfcb-4016-f5d4-99a6766dff70"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0290, 0.4019, 0.2598],\n",
              "         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n",
              " tensor([[0.0518, 0.4681, 0.6738],\n",
              "         [0.3315, 0.7837, 0.5631]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors)."
      ],
      "metadata": {
        "id": "eWoXJX70JBpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_out = torch.matmul(tensor_A, tensor_B.T)\n",
        "tensor_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_brWYvqCJEk5",
        "outputId": "672bb6ad-e359-419d-b2bb-9d3c3bfd00a2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3647, 0.4709],\n",
              "        [0.5184, 0.5617]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Find the maximum and minimum values of the output of 7.\n"
      ],
      "metadata": {
        "id": "d5Ltl3K8Jdjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(tensor_out), torch.min(tensor_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_51_xV8DJjJ7",
        "outputId": "7aea1170-b94e-493d-b55d-c44140ab9eb7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5617, device='cuda:0'), tensor(0.3647, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Find the maximum and minimum index values of the output of 7.\n"
      ],
      "metadata": {
        "id": "CWcnBlD6JhuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(tensor_out), torch.argmin(tensor_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug-gHwrRJhgq",
        "outputId": "9502764a-ba65-4c95-fd2a-a7dc39a73ade"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3, device='cuda:0'), tensor(0, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape."
      ],
      "metadata": {
        "id": "VhgW6gzBJiAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(7)\n",
        "\n",
        "tensor_rand = torch.rand(size=(1, 1, 1, 10))\n",
        "tensor_rand_2 = tensor_rand.squeeze()\n",
        "\n",
        "tensor_rand, tensor_rand.shape, tensor_rand_2, tensor_rand_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr87QTTRJheA",
        "outputId": "1e541a78-60d5-4ab3-e5f8-19922bbd7f92"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
              "            0.3653, 0.8513]]]]),\n",
              " torch.Size([1, 1, 1, 10]),\n",
              " tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
              "         0.8513]),\n",
              " torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    }
  ]
}